{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete, Discrete\n",
    "from gymnasium import Env\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "# 0 means empty - add 0 at 0th index\n",
    "numbers = [\n",
    "    c * 10 + d \n",
    "    for c, d in permutations(range(1,4), 2)\n",
    "]\n",
    "numbers.insert(0, 0) \n",
    "\n",
    "# possible AB's - add 0 at 0th index\n",
    "AB = ['0', '0A1B', '0A2B', '1A0B', '2A0B']\n",
    "\n",
    "\n",
    "# calculate number of AB\n",
    "def determine_AB(a, b):\n",
    "        a_digits = [a//10, a%10]\n",
    "        b_digits = [b//10, b%10]\n",
    "        A = 0\n",
    "        B = 0\n",
    "        for count, digit in enumerate(a_digits):\n",
    "            if digit == b_digits[count]:\n",
    "                A += 1\n",
    "            elif digit in b_digits:\n",
    "                B += 1\n",
    "        det_AB = AB.index(str(A)+'A'+str(B)+'B')\n",
    "        return det_AB\n",
    "\n",
    "class BullsnCows(Env):\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "    '''\n",
    "    State Space:\n",
    "        num_guesses*2 grid, each row 4-digit sequence + no. of AB\n",
    "        compressed into an array - so starting from zero, even indexes are the 4-digit sequence, while odd indexes are the no. of AB\n",
    "        Initialize with all 0's (empty)\n",
    "    Action Space:\n",
    "        4-digit sequence\n",
    "    Reward:\n",
    "        +1 for 4A, -1 for not getting 4A within num_guesses tries, 0 otherwise\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(BullsnCows, self).__init__()\n",
    "        # state space\n",
    "        obs_row = np.array([len(numbers), len(AB)])\n",
    "        self.observation_space = MultiDiscrete(np.concatenate(np.repeat(obs_row[np.newaxis, :], 3, axis=0)))\n",
    "        # action space - size is total number of possible numbers\n",
    "        self.action_space = Discrete(len(numbers)-1)\n",
    "        # initialize number of guesses\n",
    "        self.num_guesses = 0\n",
    "        # initialize numbers that have already been guessed\n",
    "        self.guesses = []\n",
    "        # initialize starting state - start with all zeros (empty)\n",
    "        self.state = np.zeros(2*3, dtype=int)\n",
    "        # generate correct word - exclude 0\n",
    "        self.correct_word = np.random.choice(numbers[1:len(numbers)])\n",
    "        # initialize terminated, truncated\n",
    "        self.terminated = False\n",
    "        self.truncated = False\n",
    "\n",
    "    def step(self, action):\n",
    "        # append to guesses\n",
    "        # since 0 means empty, we add one\n",
    "        action = action+1\n",
    "        self.guesses.append(action)\n",
    "\n",
    "        # go to the number guessed for the correct turn\n",
    "        self.state[2*self.num_guesses] = action\n",
    "        # map action to corresponding number and calculate to the number of AB\n",
    "        check_AB = determine_AB(numbers[action], self.correct_word)\n",
    "        self.state[2*self.num_guesses + 1] = check_AB\n",
    "        # increase number of guesses by 1\n",
    "        self.num_guesses += 1\n",
    "\n",
    "        # calculate reward - if guessed the correct word, terminate\n",
    "        if check_AB == AB.index('2A0B'):\n",
    "            reward = 1\n",
    "            self.terminated = True\n",
    "        # if it is the final guess, terminate\n",
    "        elif self.num_guesses == 3:\n",
    "            reward = -1\n",
    "            self.terminated = True\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return self.state, reward, self.terminated, self.truncated, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # reset to original states\n",
    "        # initialize number of guesses\n",
    "        self.num_guesses = 0\n",
    "        # initialize guessed numbers\n",
    "        self.guesses = []\n",
    "        # initialize starting state\n",
    "        self.state = np.zeros(2*3, dtype=int)\n",
    "        # generate correct word\n",
    "        self.correct_word = np.random.choice(numbers[1:len(numbers)])\n",
    "        # initialize terminated\n",
    "        self.terminated = False\n",
    "\n",
    "        return self.state, {}\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        print(\"Correct Word:\", self.correct_word)\n",
    "        for n, guess, state in zip([x+1 for x in range(self.num_guesses)], self.guesses, [self.state[2*i+1] for i in range(self.num_guesses)]):\n",
    "            print(f'Guess {n}: {numbers[guess]}, AB: {AB[state]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "logdir_dqn = \"reduced_logs/dqn/\"\n",
    "logdir_ppo = \"reduced_logs/ppo/\"\n",
    "logdir_a2c = \"reduced_logs/a2c/\"\n",
    "\n",
    "for logdir in [logdir_a2c, logdir_dqn, logdir_ppo]:\n",
    "\tif not os.path.exists(logdir):\n",
    "\t\tos.makedirs(logdir)\n",
    "\n",
    "env = BullsnCows()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_dqn = DQN(\"MlpPolicy\", env, verbose=1, learning_starts=50000, tensorboard_log=logdir_dqn, device=device)\n",
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir_ppo, device=device)\n",
    "model_a2c = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir_a2c, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dqn.learn(total_timesteps=100000, log_interval=4)\n",
    "model_dqn.save(\"dqn_BullsnCows_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_dqn.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ppo.learn(total_timesteps=100000, log_interval=4)\n",
    "model_ppo.save(\"ppo_BullsnCows_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_ppo.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a2c.learn(total_timesteps=100000, log_interval=4)\n",
    "model_a2c.save(\"a2c_BullsnCows_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_ppo.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='reduced_logs' --port 6007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
