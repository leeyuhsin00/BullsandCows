{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete, Discrete\n",
    "from gymnasium import Env\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "# initialize possible numbers - all digits must be distinct\n",
    "numbers = [c * 10 + d for\n",
    "    c, d in permutations(range(4), 2)]\n",
    "\n",
    "# A - digit was explored and was at the correct position\n",
    "# B - digit was explored but was at the wrong position\n",
    "# N - digit was explored but was not in the correct number\n",
    "def determine_ABN(a, b):\n",
    "        a_digits = [a//10, a%10]\n",
    "        b_digits = [b//10, b%10]\n",
    "        A = []\n",
    "        B = []\n",
    "        N = []\n",
    "        for count, digit in enumerate(a_digits):\n",
    "            if digit == b_digits[count]:\n",
    "                A.append(digit)\n",
    "            elif digit in b_digits:\n",
    "                B.append(digit)\n",
    "            else:\n",
    "                N.append(digit)\n",
    "        return A, B, N\n",
    "\n",
    "num_digits = 4\n",
    "total_guesses = 3 + 1\n",
    "\n",
    "class BullsnCows(Env):\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "    '''\n",
    "    State Space:\n",
    "        [4] * len(num_digits) + [total_guesses]  array, the number at each index corresponds to A, B, N\n",
    "        Map N to 1, B to 2, A to 3\n",
    "        Initialize with all 0 - unexplored\n",
    "    Action Space:\n",
    "        Any possible number from numbers\n",
    "    Reward:\n",
    "        +1 for 3's at the correct digits\n",
    "        -1 for not achieving the above within total_guesses-1 \n",
    "        0 otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super(BullsnCows, self).__init__()\n",
    "        # state space\n",
    "        self.observation_space = MultiDiscrete((np.array([4]*num_digits + [total_guesses])))\n",
    "        # action space - size is total number of possible numbers\n",
    "        self.action_space = Discrete(len(numbers))\n",
    "        # initialize numbers that have already been guessed (for rendering)\n",
    "        self.guesses = []\n",
    "        # for initialize digits guessed at each step (for render)\n",
    "        self.guesses_digits = []\n",
    "        # initialize the states that have been explored (for render)\n",
    "        self.explored_states = []\n",
    "\n",
    "        # initialize starting state - start with all zeros (unexplored)\n",
    "        self.state = np.zeros(num_digits+1, dtype=int)\n",
    "        # last element starts from the total number of guesses\n",
    "        self.state[-1] = total_guesses-1\n",
    "        # initialize ABN for each guess (for render)\n",
    "        self.ABN = np.zeros(num_digits)\n",
    "\n",
    "        # generate correct word \n",
    "        self.correct_word = np.random.choice(numbers)\n",
    "        # initialize correct digits to be 3\n",
    "        self.correct_digits = [self.correct_word//10, self.correct_word%10]\n",
    "\n",
    "        # initialize terminated, truncated\n",
    "        self.terminated = False\n",
    "        self.truncated = False\n",
    "\n",
    "    def step(self, action):\n",
    "        # append to guesses\n",
    "        self.guesses.append(action)\n",
    "        \n",
    "        # find the digits of the number (in order)\n",
    "        guess_digits = [numbers[action]//10, numbers[action]%10]\n",
    "        self.guesses_digits.append(guess_digits)\n",
    "\n",
    "        # map action to corresponding number and calculate to the number of ABN\n",
    "        A, B, N = determine_ABN(numbers[action], self.correct_word)\n",
    "        # if A - means correct digit correct position, map to 3\n",
    "        for index in A:\n",
    "            self.ABN[index] = 3\n",
    "            self.state[index] = 3\n",
    "        # if B - means correct digit wrong position, map to 2\n",
    "        for index in B:\n",
    "            self.ABN[index] = 2\n",
    "            # if the digit has already been explored and achieved A, we already know its correct position, so it stays at 3\n",
    "            if self.state[index] != 3:\n",
    "                self.state[index] = 2\n",
    "        # if N - means wrong digit, map to 1\n",
    "        for index in N:\n",
    "            self.ABN[index] = 1\n",
    "            self.state[index] = 1\n",
    "\n",
    "        # decrease remaining number of guesses by 1\n",
    "        self.state[-1] -= 1\n",
    "        current_ABN = self.ABN.copy()\n",
    "\n",
    "        # append to explored states\n",
    "        self.explored_states.append(current_ABN)\n",
    "\n",
    "        # calculate reward - if the correct digits have all been found at the correct positions, terminate\n",
    "        if np.all([self.state[i] == 3 for i in self.correct_digits]):\n",
    "            reward = 1\n",
    "            self.terminated = True\n",
    "        # else if it is the final guess, terminate\n",
    "        elif self.state[-1] == 0:\n",
    "            reward = -1\n",
    "            self.terminated = True\n",
    "        else:\n",
    "            reward = 0\n",
    "        return self.state, reward, self.terminated, self.truncated, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # reset to original states\n",
    "        # initialize numbers that have already been guessed (for rendering)\n",
    "        self.guesses = []\n",
    "        # for initialize digits guessed at each step (for render)\n",
    "        self.guesses_digits = []\n",
    "        # initialize the states that have been explored (for render)\n",
    "        self.explored_states = []\n",
    "\n",
    "        # initialize starting state - start with all zeros (unexplored)\n",
    "        self.state = np.zeros(num_digits+1, dtype=int)\n",
    "        # last element starts from the total number of guesses\n",
    "        self.state[-1] = total_guesses-1\n",
    "        # initialize ABN for each guess (for render)\n",
    "        self.ABN = np.zeros(num_digits)\n",
    "\n",
    "        # generate correct word \n",
    "        self.correct_word = np.random.choice(numbers)\n",
    "        # initialize correct digits to be 3\n",
    "        self.correct_digits = [self.correct_word//10, self.correct_word%10]\n",
    "\n",
    "        # initialize terminated, truncated\n",
    "        self.terminated = False\n",
    "        self.truncated = False\n",
    "\n",
    "        return self.state, {}\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        print(\"Correct Word:\", self.correct_word)\n",
    "        for n, guess, guess_digits, state in zip([x+1 for x in range(total_guesses-1-self.state[-1])], self.guesses, self.guesses_digits, self.explored_states):\n",
    "            current_explored_state = [state[i] for i in guess_digits]\n",
    "            ABN_result = []\n",
    "            for x in current_explored_state:\n",
    "                if x == 3:\n",
    "                    ABN_result.append('A')\n",
    "                elif x == 2:\n",
    "                    ABN_result.append('B')\n",
    "                else:\n",
    "                    ABN_result.append('N')\n",
    "            print(f'Guess {n}: {numbers[guess]}, ABN: {ABN_result}')\n",
    "        if np.all([self.state[i] == 3 for i in self.correct_digits]):\n",
    "            print(f'Guess {n+1}: {self.correct_word}, You win!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "logdir_dqn = \"alternative_reduced_logs/dqn/\"\n",
    "logdir_ppo = \"alternative_reduced_logs/ppo/\"\n",
    "logdir_a2c = \"alternative_reduced_logs/a2c/\"\n",
    "\n",
    "for logdir in [logdir_a2c, logdir_dqn, logdir_ppo]:\n",
    "\tif not os.path.exists(logdir):\n",
    "\t\tos.makedirs(logdir)\n",
    "\n",
    "env = BullsnCows()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_dqn = DQN(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir_dqn, device=device)\n",
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir_ppo, device=device)\n",
    "model_a2c = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir_a2c, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a2c.learn(total_timesteps=100000, log_interval=4)\n",
    "model_a2c.save(\"a2c_BullsnCows_alt_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_a2c.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dqn.learn(total_timesteps=100000, log_interval=4)\n",
    "model_dqn.save(\"dqn_BullsnCows_alt_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_dqn.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ppo.learn(total_timesteps=100000, log_interval=4)\n",
    "model_ppo.save(\"ppo_BullsnCows_alt_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "while not env.terminated:\n",
    "    action, _states = model_ppo.predict(state, deterministic=True)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='alternative_reduced_logs' --port 6012"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
